"""
Semantic Interpretation & Uncertainty Resolution
Phase 13, Steps 281-295

Implements:
- EpistemicGap dataclass (5 types) (281)
- EpistemicGapFiller with source ranking (282)
- Epistemic→Socratic escalation (283)
- AleatoricNoise dataclass (4 types) (284)
- AleatoricNoiseResolver (285)
- Distribution modeling (286)
- UncertaintyResolver pipeline (287)
- Uncertainty tracking in context (288)
- Meaning expansion (RheoMode) (289)
- Interpretation confidence (290)
- Feedback surface (291)
- Clarification protocol (292)
- Interpretation history (293)
"""

from __future__ import annotations

import hashlib
import random
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum, auto
from typing import Any, Optional, Callable
from abc import ABC, abstractmethod


# =============================================================================
# Step 281: Epistemic Gap Types
# =============================================================================

class EpistemicGapType(Enum):
    """
    Five types of epistemic uncertainty (reducible through knowledge).
    """
    MISSING_FACT = "missing_fact"           # Known unknown fact
    AMBIGUOUS_TERM = "ambiguous_term"       # Term with multiple meanings
    IMPLICIT_ASSUMPTION = "implicit"        # Unstated assumption
    LOGICAL_GAP = "logical_gap"             # Missing reasoning step
    CONTEXTUAL_UNKNOWN = "contextual"       # Missing context


class GapSeverity(Enum):
    """Severity of an epistemic gap."""
    MINOR = 1       # Can proceed with reasonable default
    MODERATE = 2    # Should clarify but can hypothesize
    MAJOR = 3       # Must resolve before proceeding
    CRITICAL = 4    # Blocks all meaningful progress


@dataclass
class EpistemicGap:
    """
    Represents a gap in knowledge that can potentially be filled.
    """
    id: str
    gap_type: EpistemicGapType
    description: str
    severity: GapSeverity = GapSeverity.MODERATE
    
    # Context
    source_text: Optional[str] = None
    location: Optional[str] = None
    
    # State
    filled: bool = False
    fill_value: Optional[str] = None
    fill_source: Optional[str] = None
    fill_confidence: float = 0.0
    
    # Relationships
    related_gap_ids: list[str] = field(default_factory=list)
    blocks_interpretation_ids: list[str] = field(default_factory=list)
    
    # Metadata
    detected_at: datetime = field(default_factory=datetime.utcnow)
    filled_at: Optional[datetime] = None
    
    def fill(self, value: str, source: str, confidence: float = 0.8) -> None:
        """Fill the gap with a value."""
        self.filled = True
        self.fill_value = value
        self.fill_source = source
        self.fill_confidence = confidence
        self.filled_at = datetime.utcnow()


# =============================================================================
# Step 282: Epistemic Gap Filler with Source Ranking
# =============================================================================

class SourceType(Enum):
    """Types of knowledge sources."""
    EXPLICIT_STATEMENT = "explicit"       # Directly stated
    INFERENCE = "inference"               # Logically inferred
    EXTERNAL_KNOWLEDGE = "external"       # Retrieved from KB
    DIALOGUE_CLARIFICATION = "dialogue"   # User clarification
    DEFAULT_ASSUMPTION = "default"        # Reasonable default
    LLM_GENERATION = "llm"                # Generated by LLM


@dataclass
class KnowledgeSource:
    """A source of knowledge for filling gaps."""
    source_id: str
    source_type: SourceType
    reliability: float = 0.8  # 0-1
    recency: float = 1.0      # 0-1, how recent
    context_match: float = 1.0  # 0-1, how well it matches context
    
    def score(self) -> float:
        """Calculate overall source score."""
        weights = {"reliability": 0.4, "recency": 0.3, "context_match": 0.3}
        return (
            self.reliability * weights["reliability"] +
            self.recency * weights["recency"] +
            self.context_match * weights["context_match"]
        )


class EpistemicGapFiller:
    """
    Fills epistemic gaps using ranked knowledge sources.
    """
    
    def __init__(self):
        self.sources: list[KnowledgeSource] = []
        self.fill_strategies: dict[EpistemicGapType, Callable] = {
            EpistemicGapType.MISSING_FACT: self._fill_missing_fact,
            EpistemicGapType.AMBIGUOUS_TERM: self._fill_ambiguous_term,
            EpistemicGapType.IMPLICIT_ASSUMPTION: self._fill_implicit,
            EpistemicGapType.LOGICAL_GAP: self._fill_logical_gap,
            EpistemicGapType.CONTEXTUAL_UNKNOWN: self._fill_contextual,
        }
    
    def register_source(self, source: KnowledgeSource) -> None:
        """Register a knowledge source."""
        self.sources.append(source)
        # Keep sorted by score
        self.sources.sort(key=lambda s: s.score(), reverse=True)
    
    def fill_gap(self, gap: EpistemicGap) -> tuple[bool, Optional[str], float]:
        """
        Attempt to fill an epistemic gap.
        Returns: (success, value, confidence)
        """
        strategy = self.fill_strategies.get(gap.gap_type)
        if not strategy:
            return False, None, 0.0
        
        return strategy(gap)
    
    def _fill_missing_fact(self, gap: EpistemicGap) -> tuple[bool, Optional[str], float]:
        """Fill a missing fact gap."""
        # Try explicit sources first, then external
        for source in self.sources:
            if source.source_type in [SourceType.EXPLICIT_STATEMENT, SourceType.EXTERNAL_KNOWLEDGE]:
                # In production, would query the actual source
                return True, f"[Retrieved from {source.source_id}]", source.reliability
        
        # Fall back to LLM generation
        return True, "[LLM-generated fact]", 0.5
    
    def _fill_ambiguous_term(self, gap: EpistemicGap) -> tuple[bool, Optional[str], float]:
        """Fill an ambiguous term gap."""
        # Prefer dialogue clarification
        for source in self.sources:
            if source.source_type == SourceType.DIALOGUE_CLARIFICATION:
                return True, f"[Clarified: {gap.source_text}]", 0.95
        
        # Use context to disambiguate
        return True, f"[Disambiguated by context]", 0.7
    
    def _fill_implicit(self, gap: EpistemicGap) -> tuple[bool, Optional[str], float]:
        """Fill an implicit assumption gap."""
        # Make explicit and seek confirmation
        return True, f"[Implicit assumption made explicit]", 0.6
    
    def _fill_logical_gap(self, gap: EpistemicGap) -> tuple[bool, Optional[str], float]:
        """Fill a logical gap."""
        return True, f"[Inferred missing step]", 0.75
    
    def _fill_contextual(self, gap: EpistemicGap) -> tuple[bool, Optional[str], float]:
        """Fill a contextual unknown gap."""
        for source in self.sources:
            if source.context_match > 0.8:
                return True, f"[Context retrieved from {source.source_id}]", source.context_match
        
        return False, None, 0.0
    
    def prioritize_gaps(self, gaps: list[EpistemicGap]) -> list[EpistemicGap]:
        """Prioritize gaps by severity and fillability."""
        def gap_priority(gap: EpistemicGap) -> float:
            # Higher severity = higher priority
            severity_score = gap.severity.value / 4.0
            
            # Fillability estimate
            fillability = 0.5  # Default
            if gap.gap_type == EpistemicGapType.AMBIGUOUS_TERM:
                fillability = 0.9  # Usually can disambiguate
            elif gap.gap_type == EpistemicGapType.MISSING_FACT:
                fillability = 0.7  # Often can find
            
            return severity_score * 0.7 + fillability * 0.3
        
        return sorted(gaps, key=gap_priority, reverse=True)


# =============================================================================
# Step 283: Epistemic → Socratic Escalation
# =============================================================================

@dataclass
class SocraticEscalation:
    """An escalation to Socratic dialogue for gap resolution."""
    gap_id: str
    question: str
    question_type: str  # 'clarification', 'definition', 'justification'
    priority: int = 5
    answered: bool = False
    answer: Optional[str] = None


class EpistemicToSocraticBridge:
    """
    Escalates unfillable epistemic gaps to Socratic questioning.
    """
    
    def __init__(self):
        self.escalations: list[SocraticEscalation] = []
        self.question_templates = {
            EpistemicGapType.MISSING_FACT: [
                "What do you know about {topic}?",
                "Can you provide more detail about {topic}?",
            ],
            EpistemicGapType.AMBIGUOUS_TERM: [
                "When you say '{term}', do you mean A or B?",
                "Can you clarify what '{term}' means in this context?",
            ],
            EpistemicGapType.IMPLICIT_ASSUMPTION: [
                "Are you assuming that {assumption}?",
                "What assumptions are you making about {topic}?",
            ],
            EpistemicGapType.LOGICAL_GAP: [
                "How does {A} lead to {B}?",
                "What's the reasoning connecting these ideas?",
            ],
            EpistemicGapType.CONTEXTUAL_UNKNOWN: [
                "What's the context for {topic}?",
                "Can you provide background on {topic}?",
            ],
        }
    
    def escalate(self, gap: EpistemicGap) -> SocraticEscalation:
        """Create a Socratic escalation for an unfilled gap."""
        templates = self.question_templates.get(gap.gap_type, ["Can you clarify?"])
        template = templates[0]
        
        # Fill template
        topic = gap.source_text or gap.description
        question = template.format(
            topic=topic[:50],
            term=topic[:30],
            assumption=gap.description[:50],
            A="premise",
            B="conclusion",
        )
        
        escalation = SocraticEscalation(
            gap_id=gap.id,
            question=question,
            question_type=self._determine_question_type(gap.gap_type),
            priority=gap.severity.value,
        )
        
        self.escalations.append(escalation)
        return escalation
    
    def _determine_question_type(self, gap_type: EpistemicGapType) -> str:
        """Determine question type from gap type."""
        mapping = {
            EpistemicGapType.MISSING_FACT: "clarification",
            EpistemicGapType.AMBIGUOUS_TERM: "definition",
            EpistemicGapType.IMPLICIT_ASSUMPTION: "justification",
            EpistemicGapType.LOGICAL_GAP: "justification",
            EpistemicGapType.CONTEXTUAL_UNKNOWN: "clarification",
        }
        return mapping.get(gap_type, "clarification")
    
    def record_answer(self, gap_id: str, answer: str) -> bool:
        """Record an answer to an escalation."""
        for esc in self.escalations:
            if esc.gap_id == gap_id:
                esc.answered = True
                esc.answer = answer
                return True
        return False
    
    def get_pending(self) -> list[SocraticEscalation]:
        """Get pending escalations sorted by priority."""
        pending = [e for e in self.escalations if not e.answered]
        return sorted(pending, key=lambda e: e.priority, reverse=True)


# =============================================================================
# Steps 284-286: Aleatoric Noise Types and Resolution
# =============================================================================

class AleatoricNoiseType(Enum):
    """
    Four types of aleatoric uncertainty (irreducible randomness).
    """
    MEASUREMENT_ERROR = "measurement"     # Physical measurement noise
    INHERENT_RANDOMNESS = "random"        # Truly random process
    LINGUISTIC_AMBIGUITY = "linguistic"   # Natural language ambiguity
    INCOMPLETE_OBSERVATION = "incomplete" # Partial observation


@dataclass
class AleatoricNoise:
    """
    Represents irreducible uncertainty that must be modeled, not filled.
    """
    id: str
    noise_type: AleatoricNoiseType
    description: str
    
    # Distribution modeling
    distribution_type: str = "unknown"  # 'gaussian', 'uniform', 'categorical', 'unknown'
    parameters: dict[str, float] = field(default_factory=dict)
    
    # Bounds
    min_value: Optional[float] = None
    max_value: Optional[float] = None
    possible_values: list[str] = field(default_factory=list)
    
    # Confidence
    confidence_in_distribution: float = 0.5
    
    # Metadata
    source_text: Optional[str] = None
    detected_at: datetime = field(default_factory=datetime.utcnow)


class AleatoricNoiseResolver:
    """
    Resolves aleatoric noise by EXPANDING interpretations, not filling.
    Per RheoMode principle: embrace ambiguity, don't collapse it.
    """
    
    def __init__(self):
        self.distributions: dict[str, dict] = {}
    
    def expand_interpretations(self, noise: AleatoricNoise) -> list[dict[str, Any]]:
        """
        Generate multiple interpretations for aleatoric noise.
        """
        if noise.noise_type == AleatoricNoiseType.LINGUISTIC_AMBIGUITY:
            return self._expand_linguistic(noise)
        elif noise.noise_type == AleatoricNoiseType.MEASUREMENT_ERROR:
            return self._expand_measurement(noise)
        elif noise.noise_type == AleatoricNoiseType.INHERENT_RANDOMNESS:
            return self._expand_random(noise)
        else:
            return self._expand_incomplete(noise)
    
    def _expand_linguistic(self, noise: AleatoricNoise) -> list[dict[str, Any]]:
        """Expand linguistic ambiguity into multiple readings."""
        if noise.possible_values:
            return [
                {"interpretation": val, "probability": 1.0 / len(noise.possible_values)}
                for val in noise.possible_values
            ]
        return [
            {"interpretation": "Reading A", "probability": 0.5},
            {"interpretation": "Reading B", "probability": 0.5},
        ]
    
    def _expand_measurement(self, noise: AleatoricNoise) -> list[dict[str, Any]]:
        """Expand measurement uncertainty into distribution."""
        mean = noise.parameters.get("mean", 0)
        std = noise.parameters.get("std", 1)
        
        return [
            {"value": mean - 2*std, "probability": 0.05, "label": "low_extreme"},
            {"value": mean - std, "probability": 0.15, "label": "low"},
            {"value": mean, "probability": 0.60, "label": "expected"},
            {"value": mean + std, "probability": 0.15, "label": "high"},
            {"value": mean + 2*std, "probability": 0.05, "label": "high_extreme"},
        ]
    
    def _expand_random(self, noise: AleatoricNoise) -> list[dict[str, Any]]:
        """Model inherent randomness as uniform distribution."""
        if noise.min_value is not None and noise.max_value is not None:
            # Sample points from range
            n_samples = 5
            step = (noise.max_value - noise.min_value) / (n_samples - 1)
            return [
                {"value": noise.min_value + i * step, "probability": 1.0/n_samples}
                for i in range(n_samples)
            ]
        return [{"value": "random", "probability": 1.0}]
    
    def _expand_incomplete(self, noise: AleatoricNoise) -> list[dict[str, Any]]:
        """Expand incomplete observation into possibilities."""
        return [
            {"interpretation": "observed_subset", "confidence": 0.7},
            {"interpretation": "missing_critical_part", "confidence": 0.3},
        ]
    
    def model_distribution(self, noise: AleatoricNoise, samples: list[float] = None) -> dict:
        """Model the underlying distribution."""
        if samples:
            mean = sum(samples) / len(samples)
            variance = sum((x - mean) ** 2 for x in samples) / len(samples)
            std = variance ** 0.5
            
            noise.distribution_type = "gaussian"
            noise.parameters = {"mean": mean, "std": std, "n_samples": len(samples)}
            noise.confidence_in_distribution = min(0.9, len(samples) / 100.0)
        
        self.distributions[noise.id] = {
            "type": noise.distribution_type,
            "params": noise.parameters,
            "confidence": noise.confidence_in_distribution,
        }
        
        return self.distributions[noise.id]


# =============================================================================
# Step 287: Unified Uncertainty Resolver Pipeline
# =============================================================================

@dataclass
class Interpretation:
    """A possible interpretation of uncertain content."""
    id: str
    content: str
    confidence: float
    source: str  # 'epistemic_fill', 'aleatoric_expansion', 'synthesis'
    supporting_evidence: list[str] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.utcnow)


class UncertaintyResolver:
    """
    Unified pipeline for resolving both epistemic and aleatoric uncertainty.
    """
    
    def __init__(self):
        self.epistemic_filler = EpistemicGapFiller()
        self.aleatoric_resolver = AleatoricNoiseResolver()
        self.socratic_bridge = EpistemicToSocraticBridge()
        
        self.epistemic_gaps: list[EpistemicGap] = []
        self.aleatoric_noises: list[AleatoricNoise] = []
        self.interpretations: list[Interpretation] = []
        
        # Configuration
        self.auto_fill_threshold = 0.7  # Auto-fill if confidence > threshold
        self.escalation_threshold = 0.3  # Escalate to Socratic if < threshold
    
    def add_epistemic_gap(self, gap: EpistemicGap) -> None:
        """Register an epistemic gap."""
        self.epistemic_gaps.append(gap)
    
    def add_aleatoric_noise(self, noise: AleatoricNoise) -> None:
        """Register aleatoric noise."""
        self.aleatoric_noises.append(noise)
    
    def resolve_all(self) -> dict[str, Any]:
        """
        Run the full uncertainty resolution pipeline.
        """
        results = {
            "filled_gaps": [],
            "escalated_gaps": [],
            "expanded_noises": [],
            "interpretations": [],
        }
        
        # 1. Prioritize and fill epistemic gaps
        prioritized = self.epistemic_filler.prioritize_gaps(self.epistemic_gaps)
        
        for gap in prioritized:
            if gap.filled:
                continue
            
            success, value, confidence = self.epistemic_filler.fill_gap(gap)
            
            if success and confidence >= self.auto_fill_threshold:
                gap.fill(value, "auto_fill", confidence)
                results["filled_gaps"].append({
                    "gap_id": gap.id,
                    "value": value,
                    "confidence": confidence,
                })
            elif confidence < self.escalation_threshold:
                # Escalate to Socratic
                escalation = self.socratic_bridge.escalate(gap)
                results["escalated_gaps"].append({
                    "gap_id": gap.id,
                    "question": escalation.question,
                })
        
        # 2. Expand aleatoric noises
        for noise in self.aleatoric_noises:
            expansions = self.aleatoric_resolver.expand_interpretations(noise)
            results["expanded_noises"].append({
                "noise_id": noise.id,
                "expansions": expansions,
            })
            
            # Generate interpretations from expansions
            for exp in expansions:
                interp = Interpretation(
                    id=f"interp_{noise.id}_{len(self.interpretations)}",
                    content=str(exp.get("interpretation", exp.get("value"))),
                    confidence=exp.get("probability", exp.get("confidence", 0.5)),
                    source="aleatoric_expansion",
                )
                self.interpretations.append(interp)
                results["interpretations"].append({
                    "id": interp.id,
                    "content": interp.content,
                    "confidence": interp.confidence,
                })
        
        return results
    
    def get_confidence_score(self) -> float:
        """
        Calculate overall interpretation confidence.
        """
        if not self.epistemic_gaps and not self.aleatoric_noises:
            return 1.0
        
        # Epistemic confidence: % of gaps filled
        filled_count = sum(1 for g in self.epistemic_gaps if g.filled)
        epistemic_conf = filled_count / len(self.epistemic_gaps) if self.epistemic_gaps else 1.0
        
        # Aleatoric confidence: average distribution confidence
        aleatoric_conf = 0.5
        if self.aleatoric_noises:
            aleatoric_conf = sum(n.confidence_in_distribution for n in self.aleatoric_noises) / len(self.aleatoric_noises)
        
        return epistemic_conf * 0.6 + aleatoric_conf * 0.4


# =============================================================================
# Steps 289-293: Meaning Expansion, Feedback, Clarification, History
# =============================================================================

class RheoModeExpander:
    """
    Expand meaning using RheoMode principles.
    RheoMode: Explore multiple interpretations rather than collapsing to one.
    """
    
    def expand_meaning(self, text: str, context: dict = None) -> list[dict[str, Any]]:
        """
        Generate multiple meaning expansions for text.
        """
        expansions = []
        
        # 1. Literal interpretation
        expansions.append({
            "mode": "literal",
            "interpretation": text,
            "confidence": 0.8,
        })
        
        # 2. Metaphorical reading
        expansions.append({
            "mode": "metaphorical",
            "interpretation": f"[Metaphoric reading of: {text[:50]}...]",
            "confidence": 0.5,
        })
        
        # 3. Contextual interpretation
        if context:
            expansions.append({
                "mode": "contextual",
                "interpretation": f"[In context: {text[:50]}...]",
                "confidence": 0.7,
            })
        
        # 4. Opposite/negation
        expansions.append({
            "mode": "dialectical",
            "interpretation": f"[What if not: {text[:30]}...]",
            "confidence": 0.3,
        })
        
        return expansions


@dataclass
class InterpretationFeedback:
    """Feedback surface for 'what I understood' confirmation."""
    interpretation_id: str
    what_i_understood: str
    confidence: float
    confirmed: Optional[bool] = None
    correction: Optional[str] = None
    timestamp: datetime = field(default_factory=datetime.utcnow)


class FeedbackSurface:
    """
    Provide 'what I understood' feedback to users.
    """
    
    def __init__(self):
        self.feedbacks: list[InterpretationFeedback] = []
    
    def generate_feedback(self, interpretation: Interpretation) -> InterpretationFeedback:
        """Generate feedback for user confirmation."""
        feedback = InterpretationFeedback(
            interpretation_id=interpretation.id,
            what_i_understood=f"I understood this as: {interpretation.content}",
            confidence=interpretation.confidence,
        )
        self.feedbacks.append(feedback)
        return feedback
    
    def record_confirmation(self, interpretation_id: str, confirmed: bool, correction: str = None) -> bool:
        """Record user confirmation/correction."""
        for fb in self.feedbacks:
            if fb.interpretation_id == interpretation_id:
                fb.confirmed = confirmed
                fb.correction = correction
                return True
        return False


@dataclass
class ClarificationRequest:
    """A request for clarification."""
    id: str
    question: str
    context: str
    priority: int = 5
    resolved: bool = False
    response: Optional[str] = None


class ClarificationProtocol:
    """
    Protocol for requesting clarifications.
    """
    
    def __init__(self):
        self.requests: list[ClarificationRequest] = []
    
    def create_request(self, question: str, context: str, priority: int = 5) -> ClarificationRequest:
        """Create a clarification request."""
        req = ClarificationRequest(
            id=hashlib.md5(f"{question}{datetime.utcnow()}".encode()).hexdigest()[:8],
            question=question,
            context=context,
            priority=priority,
        )
        self.requests.append(req)
        return req
    
    def resolve_request(self, request_id: str, response: str) -> bool:
        """Resolve a clarification request."""
        for req in self.requests:
            if req.id == request_id:
                req.resolved = True
                req.response = response
                return True
        return False
    
    def get_pending(self) -> list[ClarificationRequest]:
        """Get pending requests sorted by priority."""
        return sorted(
            [r for r in self.requests if not r.resolved],
            key=lambda r: r.priority,
            reverse=True,
        )


@dataclass
class InterpretationHistoryEntry:
    """An entry in interpretation history."""
    interpretation_id: str
    version: int
    content: str
    confidence: float
    changes: list[str] = field(default_factory=list)
    timestamp: datetime = field(default_factory=datetime.utcnow)


class InterpretationHistory:
    """
    Track history of interpretation changes.
    """
    
    def __init__(self):
        self.history: dict[str, list[InterpretationHistoryEntry]] = {}
    
    def record(self, interpretation: Interpretation, changes: list[str] = None) -> InterpretationHistoryEntry:
        """Record an interpretation version."""
        if interpretation.id not in self.history:
            self.history[interpretation.id] = []
        
        version = len(self.history[interpretation.id]) + 1
        
        entry = InterpretationHistoryEntry(
            interpretation_id=interpretation.id,
            version=version,
            content=interpretation.content,
            confidence=interpretation.confidence,
            changes=changes or [],
        )
        
        self.history[interpretation.id].append(entry)
        return entry
    
    def get_versions(self, interpretation_id: str) -> list[InterpretationHistoryEntry]:
        """Get all versions of an interpretation."""
        return self.history.get(interpretation_id, [])
    
    def get_evolution(self, interpretation_id: str) -> list[float]:
        """Get confidence evolution for an interpretation."""
        versions = self.history.get(interpretation_id, [])
        return [v.confidence for v in versions]


# =============================================================================
# Factory Functions
# =============================================================================

def create_epistemic_gap(
    description: str,
    gap_type: EpistemicGapType = EpistemicGapType.MISSING_FACT,
    severity: GapSeverity = GapSeverity.MODERATE,
    source_text: str = None,
) -> EpistemicGap:
    """Create an epistemic gap."""
    return EpistemicGap(
        id=hashlib.md5(f"gap_{description[:20]}".encode()).hexdigest()[:8],
        gap_type=gap_type,
        description=description,
        severity=severity,
        source_text=source_text,
    )


def create_aleatoric_noise(
    description: str,
    noise_type: AleatoricNoiseType = AleatoricNoiseType.LINGUISTIC_AMBIGUITY,
    possible_values: list[str] = None,
) -> AleatoricNoise:
    """Create aleatoric noise."""
    return AleatoricNoise(
        id=hashlib.md5(f"noise_{description[:20]}".encode()).hexdigest()[:8],
        noise_type=noise_type,
        description=description,
        possible_values=possible_values or [],
    )


__all__ = [
    # Epistemic
    "EpistemicGapType",
    "GapSeverity",
    "EpistemicGap",
    "SourceType",
    "KnowledgeSource",
    "EpistemicGapFiller",
    
    # Socratic bridge
    "SocraticEscalation",
    "EpistemicToSocraticBridge",
    
    # Aleatoric
    "AleatoricNoiseType",
    "AleatoricNoise",
    "AleatoricNoiseResolver",
    
    # Pipeline
    "Interpretation",
    "UncertaintyResolver",
    
    # RheoMode
    "RheoModeExpander",
    
    # Feedback
    "InterpretationFeedback",
    "FeedbackSurface",
    
    # Clarification
    "ClarificationRequest",
    "ClarificationProtocol",
    
    # History
    "InterpretationHistoryEntry",
    "InterpretationHistory",
    
    # Factory
    "create_epistemic_gap",
    "create_aleatoric_noise",
]
